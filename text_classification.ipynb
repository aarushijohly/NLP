{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMysYwYsF3kAP/wj90jkHWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarushijohly/NLP/blob/main/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aim: Leveraging pretrained language models for classifying text.\n",
        "\n",
        "1. Using representive pretrained task specific model\n",
        "2. Situation when no model is pretrained for a specific task: leveraging embedding model to generate feature which are them fed to a classic machine learning classifier\n",
        "3. Situation when there is no labeled data\n",
        "4. Using generative model"
      ],
      "metadata": {
        "id": "PqOIKHzXF21g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Movie review sentiment analysis using **\"twitter-roberta-base-sentiment-latest\"** on **\"rotten tomatoes\"** dataset.\n",
        "\n",
        "This model is finetuned on tweets for sentiment analysis. Although this was not trained specifically for movie reviews, we explore how this model generalizes.\n",
        "\n",
        "Embedding used: sentence-transformers/all-mpnet-base-v2"
      ],
      "metadata": {
        "id": "ocpx-LbZcjR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate sentence_transformers datasets openai"
      ],
      "metadata": {
        "id": "3gWjiUmAUDgZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers.pipelines.pt_utils import KeyDataset"
      ],
      "metadata": {
        "id": "Uqd_kCAFdf5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "data=load_dataset(\"rotten_tomatoes\")\n",
        "print(data)"
      ],
      "metadata": {
        "id": "wLA_S1h1iL-2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path=\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "\n",
        "pipe=pipeline(\n",
        "    model=model_path,\n",
        "    tokenizer=model_path,\n",
        "    return_all_scores=True,\n",
        "    device=\"cuda:0\"\n",
        ")"
      ],
      "metadata": {
        "id": "qc_f493ynkG1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=[]\n",
        "for output in tqdm(pipe(KeyDataset(data[\"test\"],\"text\")), total=len(data[\"test\"])):\n",
        "    negative_score=output[0][\"score\"]\n",
        "    positive_score=output[2][\"score\"]\n",
        "    assignment=np.argmax([negative_score,positive_score])\n",
        "    y_pred.append(assignment)"
      ],
      "metadata": {
        "id": "rnisw9qvgQ1R",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_performane(y_true, y_pred):\n",
        "    \"\"\"Create and print classification report\"\"\"\n",
        "    performance=classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
        "    )\n",
        "    print(performance)"
      ],
      "metadata": {
        "id": "BNjZk-13gQ8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_performane(data[\"test\"][\"label\"], y_pred)"
      ],
      "metadata": {
        "id": "oakYCLffgQ-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Leveraging Embeddings**"
      ],
      "metadata": {
        "id": "UI-8ivdVKtYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model=SentenceTransformer(\"sentence-transformer/all-mpnet-base-v2\")\n",
        "\n",
        "train_embeddings=model.encode(data[\"train\"][\"text\"], show_progress_bar=True)\n",
        "test_embeddings=model.encode(data[\"test\"][\"text\"], show_progress_bar=True)"
      ],
      "metadata": {
        "id": "O3kpMANOjNpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf=LogisticRegression(random_state=42)\n",
        "clf.fit(train_embeddings, data[\"train\"][\"label\"])\n",
        "\n",
        "y_pred=clf.predict(test_embedding)\n",
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ],
      "metadata": {
        "id": "hAE1DGzhKkT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification in case of data without labels:**\n",
        "\n",
        "We shall use **Zero-shot classification with embeddings** to predict labels of input text even though it was not trained on them. We describe our labels based on what they should represent."
      ],
      "metadata": {
        "id": "Ci4pinTqZJ3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_embeddings = model.encode([\"A negative review\", \"A positive review\"])\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
        "y_pred = np.argmax(sim_matrix, axis=1)\n",
        "\n",
        "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
      ],
      "metadata": {
        "id": "kpIXN78YKkPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classification With Generative Models**\n",
        "\n",
        "1. Using text-to-text transfer transformer: Using Flan-T5 model for classification"
      ],
      "metadata": {
        "id": "ugBR7svtbXor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe=pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-small\",\n",
        "    device=\"cuda:0\"\n",
        ")"
      ],
      "metadata": {
        "id": "7og5jjE5KkM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"Is the following sentence positive or negative?\"\n",
        "data=data.map(lambda example:{\"t5\": prompt+example['text']})\n",
        "data"
      ],
      "metadata": {
        "id": "9OKl2_eWJkaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=[]\n",
        "for output in tqdm(pipe(KeyDataset(data[\"test\"],\"t5\")), total=len(data[\"test\"])):\n",
        "    text=output[0][\"generated_text\"]\n",
        "    y_pred.append(0 if text==\"negative\" else 1)"
      ],
      "metadata": {
        "id": "V4ZFR1HwJkXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_performane(data[\"test\"][\"label\"], y_pred)"
      ],
      "metadata": {
        "id": "U2_6A365JkVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ChatGPT for Classification**"
      ],
      "metadata": {
        "id": "9orkr9nmXI9J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_tMqvStdKkKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n4n52MqHYV4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YaIgkAiwYV2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3XIgGlXkYV0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0biDAl0rYVx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XdnzKLXnYVvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T6JhhL4jYVs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0FG5ec9mKkH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u_MD_MF1Kj5Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}